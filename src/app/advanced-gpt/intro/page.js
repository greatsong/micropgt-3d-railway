'use client';

import { useState } from 'react';
import { useRouter } from 'next/navigation';

const STEPS = [
    {
        id: 'overview',
        title: 'MicroGPT í•´ë¶€í•™',
        emoji: 'ğŸ§¬',
        subtitle: 'ì „ì²´ êµ¬ì¡°ë¥¼ í•œëˆˆì—!',
    },
    {
        id: 'token',
        title: '1. í† í¬ë‚˜ì´ì €',
        emoji: 'ğŸ”¤',
        subtitle: 'í…ìŠ¤íŠ¸ â†” ì •ìˆ˜ ë³€í™˜',
    },
    {
        id: 'embed',
        title: '2. ì„ë² ë”© ë ˆì´ì–´',
        emoji: 'ğŸŒŒ',
        subtitle: 'ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ + ìœ„ì¹˜ ì •ë³´',
    },
    {
        id: 'attention',
        title: '3. ë©€í‹° í—¤ë“œ ì–´í…ì…˜',
        emoji: 'âœ¨',
        subtitle: 'Query, Key, Valueì˜ ì¶¤',
    },
    {
        id: 'feedforward',
        title: '4. í”¼ë“œ í¬ì›Œë“œ',
        emoji: 'ğŸ§ ',
        subtitle: 'ìƒê°ì„ ì •ë¦¬í•˜ëŠ” ì‹œê°„',
    },
    {
        id: 'block',
        title: '5. íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡',
        emoji: 'ğŸ“¦',
        subtitle: 'ì–´í…ì…˜ + í”¼ë“œ í¬ì›Œë“œ + ì”ì°¨',
    },
    {
        id: 'gpt',
        title: '6. ì „ì²´ ëª¨ë¸ (GPT)',
        emoji: 'ğŸ¤–',
        subtitle: 'ëª¨ë“  ê²ƒì„ í•˜ë‚˜ë¡œ ì¡°ë¦½!',
    },
];

const CODE_SNIPPETS = {
    token: `class Tokenizer:
    def __init__(self):
        # ê¸€ìë³„ë¡œ ê³ ìœ  ë²ˆí˜¸(ID) ë§¤í•‘
        self.stoi = { ch:i for i,ch in enumerate(chars) }
        self.itos = { i:ch for i,ch in enumerate(chars) }

    def encode(self, text):
        # í…ìŠ¤íŠ¸ â†’ ìˆ«ì ë¦¬ìŠ¤íŠ¸
        return [self.stoi[c] for c in text]

    def decode(self, ids):
        # ìˆ«ì ë¦¬ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸
        return ''.join([self.itos[i] for i in ids])

# ì‹¤í–‰ ì˜ˆì‹œ:
# encode("Hello") -> [33, 64, 71, 71, 74]`,

    embed: `class Embeddings(nn.Module):
    def __init__(self, vocab_size, n_embd):
        # 1. í† í° ì„ë² ë”© (ë‹¨ì–´ì˜ ì˜ë¯¸)
        self.token_embedding = nn.Embedding(vocab_size, n_embd)
        # 2. ìœ„ì¹˜ ì„ë² ë”© (ë‹¨ì–´ì˜ ìˆœì„œ)
        self.position_embedding = nn.Embedding(block_size, n_embd)

    def forward(self, idx):
        # idx: [Batch, Time] (ë‹¨ì–´ IDë“¤)
        
        # ê° ë‹¨ì–´ IDë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        tok_emb = self.token_embedding(idx) 
        
        # ìœ„ì¹˜(0, 1, 2...)ì •ë³´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        pos_emb = self.position_embedding(torch.arange(T, device=device))
        
        # ë‘ ë²¡í„°ë¥¼ ë”í•´ì„œ ìµœì¢… ì…ë ¥ ìƒì„±!
        return tok_emb + pos_emb`,

    attention: `class Head(nn.Module):
    def forward(self, x):
        # Q, K, V ìƒì„± (Linear Layer)
        k = self.key(x)   # (B, T, C)
        q = self.query(x) # (B, T, C)
        v = self.value(x) # (B, T, C)

        # 1. ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê³„ì‚° (ì¹œë°€ë„)
        # (B, T, C) @ (B, C, T) -> (B, T, T)
        wei = q @ k.transpose(-2, -1) * C**-0.5
        
        # 2. ë§ˆìŠ¤í‚¹ (ë¯¸ë˜ ì •ë³´ ê°€ë¦¬ê¸°)
        wei = wei.masked_fill(self.tril == 0, float('-inf'))
        
        # 3. í™•ë¥ ë¡œ ë³€í™˜ (Softmax)
        wei = F.softmax(wei, dim=-1)

        # 4. ê°€ì¤‘í•© (Value ëª¨ìœ¼ê¸°)
        out = wei @ v 
        return out`,

    feedforward: `class FeedForward(nn.Module):
    def __init__(self, n_embd):
        self.net = nn.Sequential(
            # ì°¨ì›ì„ 4ë°°ë¡œ ë»¥íŠ€ê¸° (ìƒê°ì˜ í™•ì¥)
            nn.Linear(n_embd, 4 * n_embd),
            
            # í™œì„±í™” í•¨ìˆ˜ (ReLU/GELU) -> ë¹„ì„ í˜•ì„±
            nn.ReLU(),
            
            # ë‹¤ì‹œ ì›ë˜ ì°¨ì›ìœ¼ë¡œ ì••ì¶•
            nn.Linear(4 * n_embd, n_embd),
            
            # ë“œë¡­ì•„ì›ƒ (ê³¼ì í•© ë°©ì§€)
            nn.Dropout(dropout),
        )

    def forward(self, x):
        return self.net(x)`,

    block: `class Block(nn.Module):
    def __init__(self, n_embd, n_head):
        # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ (ì†Œí†µ)
        self.sa = MultiHeadAttention(n_head, head_size)
        # í”¼ë“œ í¬ì›Œë“œ (ì •ë¦¬)
        self.ffwd = FeedForward(n_embd)
        # ì •ê·œí™” (ì•ˆì •ì„±)
        self.ln1 = nn.LayerNorm(n_embd)
        self.ln2 = nn.LayerNorm(n_embd)

    def forward(self, x):
        # ì”ì°¨ ì—°ê²° (Residual Connection)
        # x + ... : ë°°ìš´ ê²ƒë§Œ ë”í•œë‹¤!
        x = x + self.sa(self.ln1(x))
        x = x + self.ffwd(self.ln2(x))
        return x`,

    gpt: `class MicroGPT(nn.Module):
    def __init__(self):
        # 1. ì„ë² ë”©
        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(vocab_size, n_embd),
            wpe = nn.Embedding(block_size, n_embd),
            # 2. ë¸”ë¡ ìŒ“ê¸° (ê¹Šì€ ì‹ ê²½ë§)
            h = nn.ModuleList([Block(n_embd, n_head) for _ in range(n_layer)]),
            # 3. ìµœì¢… ì •ê·œí™”
            ln_f = nn.LayerNorm(n_embd),
        ))
        # 4. ì–¸ì–´ í—¤ë“œ (ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡)
        self.lm_head = nn.Linear(n_embd, vocab_size)

    def forward(self, idx):
        # ... (ì„ë² ë”© + ë¸”ë¡ í†µê³¼) ...
        x = self.transformer.ln_f(x)
        logits = self.lm_head(x)
        return logits`,
};

export default function AdvancedGPTPage() {
    const router = useRouter();
    const [currentStep, setCurrentStep] = useState(0);
    const step = STEPS[currentStep];

    const nextStep = () => setCurrentStep((s) => Math.min(s + 1, STEPS.length - 1));
    const prevStep = () => { if (currentStep > 0) setCurrentStep((s) => s - 1); };

    const renderContent = () => {
        if (step.id === 'overview') {
            return (
                <div style={ds.overviewContainer}>
                    <div style={{ fontSize: '5rem', marginBottom: 20 }} className="animate-float">ğŸ§¬</div>
                    <p style={ds.text}>
                        ì§€ê¸ˆê¹Œì§€ ë°°ìš´ <strong style={{ color: '#7c5cfc' }}>ì„ë² ë”©, ì–´í…ì…˜, ì •ê·œí™”</strong>ê°€<br />
                        ì‹¤ì œ ì½”ë“œì—ì„œëŠ” ì–´ë–»ê²Œ ì¡°ë¦½ë ê¹Œìš”?<br /><br />
                        OpenAIì˜ GPT ì‹œë¦¬ì¦ˆì™€ ë™ì¼í•œ êµ¬ì¡°ì¸<br />
                        <strong style={{ color: '#10b981' }}>Transformer Decoder</strong>ì˜<br />
                        í•µì‹¬ ì½”ë“œë¥¼ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë´…ë‹ˆë‹¤.
                    </p>
                    <div style={ds.diagramBox}>
                        <div style={ds.diagramLayer}>Output (Next Token)</div>
                        <div style={ds.arrow}>â†‘</div>
                        <div style={{ ...ds.diagramLayer, background: 'rgba(16, 185, 129, 0.2)', border: '1px solid #10b981' }}>
                            Softmax Classifier
                        </div>
                        <div style={ds.arrow}>â†‘</div>
                        <div style={{ ...ds.diagramLayer, height: 100, justifyContent: 'space-between', padding: 10, border: '2px dashed rgba(124, 92, 252, 0.4)' }}>
                            <div style={{ fontSize: '0.8rem', color: '#7c5cfc' }}>x N Blocks</div>
                            <div style={{ ...ds.diagramLayer, height: 30, fontSize: '0.8rem' }}>Feed Forward</div>
                            <div style={{ ...ds.diagramLayer, height: 30, fontSize: '0.8rem' }}>Multi-Head Attention</div>
                        </div>
                        <div style={ds.arrow}>â†‘</div>
                        <div style={{ ...ds.diagramLayer, background: 'rgba(251, 191, 36, 0.2)', border: '1px solid #fbbf24' }}>
                            Embedding + Positional Enc
                        </div>
                        <div style={ds.arrow}>â†‘</div>
                        <div style={ds.diagramLayer}>Input (Tokens)</div>
                    </div>
                </div>
            );
        }

        return (
            <div style={ds.codeContainer}>
                <div style={ds.explanationBox}>
                    <h3 style={{ fontSize: '1.1rem', color: '#fff', marginBottom: 12 }}>
                        {step.subtitle}
                    </h3>
                    <p style={{ fontSize: '0.9rem', color: 'var(--text-secondary)', whiteSpace: 'pre-line' }}>
                        {getExplanation(step.id)}
                    </p>
                </div>
                <div style={ds.codeBox}>
                    <div style={ds.codeHeader}>Python (PyTorch)</div>
                    <pre style={ds.codeBlock}>
                        {CODE_SNIPPETS[step.id]}
                    </pre>
                </div>
            </div>
        );
    };

    return (
        <div style={pageStyles.container}>
            <div style={pageStyles.progressBar}>
                {STEPS.map((s, i) => (
                    <div
                        key={s.id}
                        style={{
                            ...pageStyles.progressDot,
                            background: i <= currentStep ? 'var(--accent-nova)' : 'rgba(124, 92, 252, 0.15)',
                            transform: i === currentStep ? 'scale(1.3)' : 'scale(1)',
                        }}
                        onClick={() => setCurrentStep(i)}
                    />
                ))}
                <div style={{
                    ...pageStyles.progressFill,
                    width: `${(currentStep / (STEPS.length - 1)) * 100}%`,
                }} />
            </div>

            <div style={pageStyles.header}>
                <span style={pageStyles.weekBadge}>ì‹¬í™” ê³¼ì •</span>
                <div style={{ fontSize: '3rem' }}>{step.emoji}</div>
                <h1 style={pageStyles.title}>
                    <span className="text-gradient">{step.title}</span>
                </h1>
            </div>

            <div style={pageStyles.content}>{renderContent()}</div>

            <div style={pageStyles.navBar}>
                <button
                    className="btn-nova"
                    style={{ ...pageStyles.navBtn, opacity: currentStep === 0 ? 0.3 : 1 }}
                    onClick={prevStep}
                    disabled={currentStep === 0}
                >
                    <span>â† ì´ì „</span>
                </button>
                <span style={pageStyles.stepCount}>{currentStep + 1} / {STEPS.length}</span>
                <button className="btn-nova" style={pageStyles.navBtn} onClick={
                    currentStep < STEPS.length - 1 ? nextStep : () => router.push('/hub')
                }>
                    <span>{currentStep < STEPS.length - 1 ? 'ë‹¤ìŒ â†’' : 'ì™„ë£Œ (í—ˆë¸Œë¡œ)'}</span>
                </button>
            </div>
        </div>
    );
}

function getExplanation(id) {
    switch (id) {
        case 'token': return "ì»´í“¨í„°ëŠ” 'ì‚¬ê³¼'ë¼ëŠ” ê¸€ìë¥¼ ëª¨ë¦…ë‹ˆë‹¤.\nê·¸ë˜ì„œ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” ì‚¬ì „(Vocab)ì„ ì´ìš©í•´\nëª¨ë“  ê¸€ìë¥¼ ê³ ìœ í•œ 'ë²ˆí˜¸'ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n\nì´ê²ƒì´ LLMì˜ ì…êµ¬ì´ì ì¶œêµ¬ì…ë‹ˆë‹¤.";
        case 'embed': return "ë‹¨ì–´ ë²ˆí˜¸(idx)ë¥¼ ì…ë ¥ë°›ìœ¼ë©´,\ní•´ë‹¹ ë‹¨ì–´ì˜ 'ì˜ë¯¸ ë²¡í„°'ë¥¼ ì°¾ì•„ì˜µë‹ˆë‹¤.\n\nì—¬ê¸°ì— 'ìœ„ì¹˜ ë²¡í„°(Position)'ë¥¼ ë”í•´ì¤˜ì•¼\n'Aê°€ Bë¥¼ ë•Œë ¸ë‹¤'ì™€ 'Bê°€ Aë¥¼ ë•Œë ¸ë‹¤'ë¥¼ êµ¬ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.";
        case 'attention': return "GPTì˜ í•µì‹¬ ì—”ì§„ì…ë‹ˆë‹¤!\n\n1. Query(ì§ˆë¬¸)ì™€ Key(ë‹µë³€)ë¥¼ ê³±í•´ ê´€ë ¨ì„±ì„ ì°¾ê³ \n2. Softmaxë¡œ í™•ë¥ (Attention Score)ì„ ë§Œë“  ë’¤\n3. Value(ì •ë³´)ë¥¼ ì„ì–´ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n\nmasked_fillì€ ì»¨ë‹ ë°©ì§€(ë¯¸ë˜ ë‹¨ì–´ ë³´ì§€ ì•Šê¸°)ìš©ì…ë‹ˆë‹¤.";
        case 'feedforward': return "ì–´í…ì…˜ì´ 'ë‹¨ì–´ë“¤ë¼ë¦¬ ëŒ€í™”'í•˜ë©° ì •ë³´ë¥¼ ëª¨ì•˜ë‹¤ë©´,\ní”¼ë“œ í¬ì›Œë“œëŠ” ê° ë‹¨ì–´ê°€ í˜¼ìì„œ 'ìƒê°ì„ ì •ë¦¬'í•˜ëŠ” ì‹œê°„ì…ë‹ˆë‹¤.\n\nì°¨ì›ì„ ì ì‹œ ëŠ˜ë ¸ë‹¤ê°€(4ë°°) ì¤„ì´ë©´ì„œ,\nì •ë³´ë¥¼ ë” ë³µì¡í•˜ê³  í’ë¶€í•˜ê²Œ ê°€ê³µí•©ë‹ˆë‹¤.";
        case 'block': return "ì´ì œ 'ì–´í…ì…˜'ê³¼ 'í”¼ë“œ í¬ì›Œë“œ'ë¥¼ í•˜ë‚˜ì˜ ë¸”ë¡ìœ¼ë¡œ ë¬¶ìŠµë‹ˆë‹¤.\n\nì¤‘ìš”í•œ ì ì€ 'ì”ì°¨ ì—°ê²°(Residual +)'ì…ë‹ˆë‹¤.\nê¸°ì¡´ ì •ë³´(x)ë¥¼ ìŠì§€ ì•Šê³ , ìƒˆë¡œ ë°°ìš´ ê²ƒë§Œ ë”í•´ì¤ë‹ˆë‹¤.\nì´ ë•ë¶„ì— ê¹Šì€ ì‹ ê²½ë§ë„ í•™ìŠµì´ ì˜ ë©ë‹ˆë‹¤.";
        case 'gpt': return "ë§ˆì¹¨ë‚´ ì™„ì„±ì…ë‹ˆë‹¤!\n\nì„ë² ë”© ë ˆì´ì–´ë¥¼ ì§€ë‚˜,\níŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ì„ Në²ˆ ë°˜ë³µ(ë³´í†µ 12~96ì¸µ)í•˜ê³ ,\në§ˆì§€ë§‰ì— 'ë‹¤ìŒ ë‹¨ì–´'ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í—¤ë“œë¥¼ í†µê³¼í•©ë‹ˆë‹¤.\n\nì´ê²ƒì´ ë°”ë¡œ ChatGPTì˜ ì‹¤ì²´ì…ë‹ˆë‹¤. ìƒê°ë³´ë‹¤ ê°„ë‹¨í•˜ì£ ?";
        default: return "";
    }
}

const pageStyles = {
    container: { minHeight: '100vh', display: 'flex', flexDirection: 'column', alignItems: 'center', padding: '24px 20px', maxWidth: 680, margin: '0 auto' },
    progressBar: { display: 'flex', gap: 8, alignItems: 'center', marginBottom: 32, position: 'relative', width: '100%', maxWidth: 300, justifyContent: 'center' },
    progressDot: { width: 12, height: 12, borderRadius: '50%', cursor: 'pointer', transition: 'all 0.3s', zIndex: 1 },
    progressFill: { position: 'absolute', left: 6, top: '50%', height: 3, background: 'var(--accent-nova)', borderRadius: 2, transform: 'translateY(-50%)', transition: 'width 0.3s', zIndex: 0 },
    header: { textAlign: 'center', marginBottom: 24 },
    weekBadge: { display: 'inline-block', padding: '4px 12px', borderRadius: 20, fontSize: '0.75rem', fontWeight: 700, background: 'rgba(255, 255, 255, 0.1)', color: '#fff', marginBottom: 12, letterSpacing: '0.05em' },
    title: { fontSize: '1.6rem', fontWeight: 800, marginTop: 8, marginBottom: 6 },
    content: { flex: 1, width: '100%', marginBottom: 24 },
    navBar: { display: 'flex', alignItems: 'center', justifyContent: 'space-between', width: '100%', padding: '16px 0', borderTop: '1px solid var(--border-subtle)' },
    navBtn: { padding: '10px 24px', fontSize: '0.9rem' },
    stepCount: { fontSize: '0.85rem', color: 'var(--text-dim)', fontWeight: 600 },
};

const ds = {
    overviewContainer: { textAlign: 'center', padding: 20 },
    text: { fontSize: '1rem', color: 'var(--text-secondary)', lineHeight: 1.8 },
    diagramBox: { marginTop: 32, display: 'flex', flexDirection: 'column', alignItems: 'center', gap: 8, maxWidth: 300, margin: '32px auto 0' },
    diagramLayer: { width: '100%', padding: '12px', borderRadius: 8, border: '1px solid var(--border-subtle)', background: 'rgba(15, 10, 40, 0.5)', color: 'var(--text-primary)', fontSize: '0.9rem', fontWeight: 600, display: 'flex', alignItems: 'center', justifyContent: 'center' },
    arrow: { color: 'var(--text-dim)', fontSize: '1.2rem' },

    codeContainer: {},
    explanationBox: { padding: 20, borderRadius: 12, background: 'rgba(124, 92, 252, 0.1)', border: '1px solid rgba(124, 92, 252, 0.2)', marginBottom: 20 },
    codeBox: { borderRadius: 12, overflow: 'hidden', border: '1px solid var(--border-subtle)', background: '#1e1e1e' },
    codeHeader: { padding: '8px 16px', background: '#2d2d2d', color: '#9ca3af', fontSize: '0.8rem', fontWeight: 600, borderBottom: '1px solid #333' },
    codeBlock: { margin: 0, padding: 20, overflowX: 'auto', fontFamily: '"Fira Code", monospace', fontSize: '0.85rem', lineHeight: 1.6, color: '#e0e0e0' },
};
